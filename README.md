MLP in PyTorch with EMNIST Dataset ğŸ“Š
Welcome to this fun project where I've implemented a Multi-Layer Perceptron (MLP) using PyTorch, taking on the extensive EMNIST dataset.

ğŸ¯ Project Overview
Ever wanted to feel the thrill of training a neural network without diving into the complex architectures? Well, look no further! This project is a light-hearted attempt at using PyTorch to whip up an MLP that munches on EMNIST data like it's candy. ğŸ¬

ğŸ“¦ What's Inside
Neural Network Nirvana: Simple, concise, yet effective implementation of an MLP using the majestic powers of PyTorch.
Dataset Delights: Harnessing the EMNIST dataset â€“ because why deal with 10 digits when there are letters to play with?

ğŸ‰ Fun Fact
Did you know? The EMNIST dataset is like the MNIST's cooler, elder sibling. While MNIST boasts 10 classes, EMNIST struts in with 62! Now that's a lot of learning material for our young MLP.

ğŸ“¢ Shoutout
Big thanks to PyTorch for making neural network crafting feel like playing with LEGO, and the creators of EMNIST for expanding our horizons beyond digits.
