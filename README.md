MLP in PyTorch with EMNIST Dataset 📊
Welcome to this fun project where I've implemented a Multi-Layer Perceptron (MLP) using PyTorch, taking on the extensive EMNIST dataset.

🎯 Project Overview
Ever wanted to feel the thrill of training a neural network without diving into the complex architectures? Well, look no further! This project is a light-hearted attempt at using PyTorch to whip up an MLP that munches on EMNIST data like it's candy. 🍬

📦 What's Inside
Neural Network Nirvana: Simple, concise, yet effective implementation of an MLP using the majestic powers of PyTorch.
Dataset Delights: Harnessing the EMNIST dataset – because why deal with 10 digits when there are letters to play with?

🎉 Fun Fact
Did you know? The EMNIST dataset is like the MNIST's cooler, elder sibling. While MNIST boasts 10 classes, EMNIST struts in with 62! Now that's a lot of learning material for our young MLP.

📢 Shoutout
Big thanks to PyTorch for making neural network crafting feel like playing with LEGO, and the creators of EMNIST for expanding our horizons beyond digits.
